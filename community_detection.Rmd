---
title: "Community Detection"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidygraph)
library(ggraph)
library(igraph)
library(visNetwork)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
source("DB_connection.R")
```

## Load Data

Load data for a specific subreddit and a time period. 

As pre-processing is necessary to exclude the post where the user or author is [deleted]. This users add relations between users that are not real and change the generation of the communities

```{r dataload, echo=FALSE}
databaseName <- "reddit"
collectionName <- "stocks"
initial_time <-"2020-11-03"
end_time <-"2020-11-07"

raw_data <- loadDataDates(databaseName,collectionName,initial_time,end_time) %>%
  filter(user!="[deleted]") #,author!="[deleted]"

#for authors that hava name [deleted] a new name is assigned with the structure "author_number"
new_authors_names <-raw_data %>%
  filter(author=="[deleted]") %>%
  distinct(link) %>%
  mutate(author_name = paste0("author_",row_number(.)))

raw_data <-raw_data %>%
  left_join(., new_authors_names, by=c( "link"="link")) %>%
  mutate(author = ifelse(author == "[deleted]", author_name, author))

head(raw_data)

```


## Graph creation

Creation of the undirected graph with the two different interactions:
-> comment on the posts 
-> nested comments between users about a post

The weight is determined by the amount or comments between a pair of users 

```{r graphCreation, echo=FALSE}
comments_posts <- raw_data %>%
  filter(!grepl("_",structure)) %>%
  rename(
    from = user,
    to = author
  )%>%
  subset( select = c(from,to))

nested_comments <-raw_data %>% 
  mutate(
    from = structure,
    to = gsub("^(.*)_\\d+$", "\\1", structure) 
  )%>%
  subset( select = c(user,from,to,link))%>%
  left_join(., ., by=c( "link"="link","from"="to")) %>% 
  drop_na("user.y") %>%
  select("from"=user.y, "to"=user.x) 

connections <-rbind(comments_posts, nested_comments) %>% 
  filter(from!=to) %>% 
  group_by(from, to) %>%
  summarise(weight = n()) %>% 
  ungroup() %>%
  mutate(width = weight+5)

#create igraph object
#First two columns work as edge list and the others as weight 
g <- graph_from_data_frame(connections,directed=FALSE)

#plot graph
g %>%
  plot(vertex.label=NA, vertex.color="blue", vertex.size=5)
```


##Community creation

Create community with the Louvain community detection algorithm and create a visualization of the graphics with the VisNetwork library. For that purpose the set of nodes are retrieved from the original graph and the community where each user belong is obtained from the communities that are created

```{r community, echo=FALSE}

lc <- cluster_louvain(g)
communities_lc <-communities(lc)

# Get nodes and edges for the creation of the visualization of the community
nodes <-do.call(rbind.data.frame, as.list(V(g)$name))
nodes$group =membership(lc)
colnames(nodes)<-c('id','group')
nodes$labels = nodes$id

edges <- get.data.frame(g, what= c("edges") )
visNetwork(nodes, edges)%>%
 # visOptions(selectedBy = "group", 
 #             highlightNearest = TRUE) %>%
  visClusteringByGroup(groups = unique(nodes$group), label="cluster: ")
```
For each community the most common words are extracted

```{r relevantWordsComm, echo=FALSE}
#function to retrieve the most relevant words for each community
get_relevant_words_community <- function(community) {
  posts_community <- subset(raw_data,user %in% as.list(communities_lc[[community]])|author %in%
                              as.list(communities_lc[[community]]))
  single_posts <- unique(posts_community$post_text)
  TextDoc <- Corpus(VectorSource(c(posts_community$comment,single_posts)))
  # pre processing of data
  #Replacing "/", "@" and "|" with space
  toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
  TextDoc <- tm_map(TextDoc, toSpace, "/")
  TextDoc <- tm_map(TextDoc, toSpace, "@")
  TextDoc <- tm_map(TextDoc, toSpace, "\\|")
  # Convert the text to lower case
  TextDoc <- tm_map(TextDoc, content_transformer(tolower))
  # Remove numbers
  TextDoc <- tm_map(TextDoc, removeNumbers)
  # Remove english common stopwords
  TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
  # Remove punctuations
  TextDoc <- tm_map(TextDoc, removePunctuation)
  # Eliminate extra white spaces
  TextDoc <- tm_map(TextDoc, stripWhitespace)
  
  # Build a term-document matrix
  TextDoc_dtm <- TermDocumentMatrix(TextDoc)
  dtm_m <- as.matrix(TextDoc_dtm)
  # Sort by descearing value of frequency
  dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
  dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
  words_community <-head(dtm_d, 3)$word
  return(paste(words_community, collapse = ','))
}


```

```{r descriptionComm, echo=FALSE,warning = FALSE}
description_communities <- rep(NA, length(communities_lc))
for (i in 1:length(communities_lc)) {
  description_communities[[i]]<- get_relevant_words_community(i)
}
description_communities

#nodes
```

```{r, echo=FALSE}
new_nodes <-transform(nodes, description = description_communities[group])
colnames(new_nodes)<-c('id','group_id','label','group')
new_nodes <- subset( new_nodes, select = -group_id ) %>%
    mutate(title = paste0("<p><b>", label,"</b><br>Node !</p>"))

plotCommunities <-visNetwork(new_nodes, edges, background="silver")%>%
  #visNodes(shape = "icon",icon=list(code = "f007")) %>%
  visClusteringByGroup(groups = unique(new_nodes$group), label="keywords: ")%>% 
  visNodes(title = as.list(unique(new_nodes$group)))%>%
  visInteraction(navigationButtons = TRUE)%>% 
  addFontAwesome()

#plotCommunities$x

plotCommunities

# library(htmltools)
# browsable(
#   tagList(
#     tags$head(
#       tags$style('div.vis-network{background-color: silver;}')  
#     ),
#     plotCommunities
#   )
# )
```


Check data with users deteled


```{r dataAnalysis, echo=FALSE}
databaseName <- "reddit"
collectionName <- "stocks"
#get all the interactions with 
deleted_comments <-getPostDeletedUser(databaseName,collectionName)
colnames(deleted_comments) <- c('dates','deleted_users')
deletedUsers_Authors <-getDeletedPost(databaseName,collectionName)
colnames(deletedUsers_Authors) <- c('dates','deleted_auth_users')
post_per_day <-getPostPerDay(databaseName,collectionName)
colnames(post_per_day) <- c('dates','total_comments')



merged_data <- merge(x = post_per_day, y = deleted_comments, 
                    by = "dates", all = TRUE) %>%
  merge(.,deletedUsers_Authors, by="dates",all=TRUE) 
              
merged_data[is.na(merged_data)] <- 0
merged_data$percentageLost <- merged_data$deleted_users / merged_data$total_comments
merged_data$percentageAuthorUsers <- merged_data$deleted_auth_users / merged_data$total_comments

ggplot(data=merged_data, aes(x=dates, group=1)) +
  geom_line(aes(y=percentageLost), color="darkred")+
  geom_line(aes(y=percentageAuthorUsers), color="steelblue")



``` 



